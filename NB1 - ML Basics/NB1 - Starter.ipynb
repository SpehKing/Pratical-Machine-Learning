{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee2d3b9",
   "metadata": {},
   "source": [
    "# Lab work 1 : Machine Learning Basics\n",
    "\n",
    "This notebook builds on the first lecture of Foundations of Machine Learning. We'll focus on the preprocessing pipeline, the actual models will come later, but for now, you'll see how each step gets us closer to a proper model.\n",
    "\n",
    "Important note: the steps shown here are not always the most efficient or the most “industry-approved.” Their main purpose is pedagogical. So don't panic if something looks suboptimal—it's meant to be.\n",
    "\n",
    "If you have questions (theoretical or practical), don't hesitate to bug your lecturer.\n",
    "\n",
    "We will try to accurately predict the price of a diamond based on a [dataset]((https://www.kaggle.com/datasets/shivam2503/diamonds)). Let's first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5625cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NB1 - Diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab915452",
   "metadata": {},
   "source": [
    "Before diving into the dataset, notice that the column *Unnamed: 0* doesn't seem to carry any useful information.\n",
    "\n",
    "**Task** : Use the [`drop`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method to remove the *Unnamed: 0* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb953b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5bbb01e",
   "metadata": {},
   "source": [
    "Here are the columns we'll be working with:\n",
    "\n",
    "* **price** : price in US dollars ($326-$18,823)\n",
    "* **carat** : weight of the diamond (0.2-5.01)\n",
    "* **cut** : quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "* **color** : diamond colour, from J (worst) to D (best)\n",
    "* **clarity** : a measurement of how clear the diamond is from I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, to IF (best)\n",
    "* **x** : length in mm (0-10.74)\n",
    "* **y** : width in mm (0-58.9)\n",
    "* **z** : depth in mm (0-31.8)\n",
    "* **depth** : total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43-79)\n",
    "* **table** : width of top of diamond relative to widest point (43-95)\n",
    "\n",
    "We're all eager to jump into machine learning, so let's build our very first linear regressor!\n",
    "\n",
    "## My first model !\n",
    "\n",
    "We know that a linear regression only works with numerical inputs. So, in this case, we can use the columns *carat*, *x*, *y*, *z*, *depth* and *table* to predict the target column *price*. \n",
    "\n",
    "**Task** : From the dataframe *df*, extract a matrice *X* (the features) and a vector *y* (the target). Then use [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split *X* and *y* into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a3334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9073a5f0",
   "metadata": {},
   "source": [
    "Now that we have our training and test sets, it's time to train and evaluate! We'll measure performance with two metrics: [`RMSE`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) and [`MAE`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error).\n",
    "\n",
    "\n",
    "**Task** : Using the [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class, fit a model on the training set. Then use the `predict` method to make predictions on the test set and print out performance for both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0a091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25013194",
   "metadata": {},
   "source": [
    "So... is our model actually any good?\n",
    "\n",
    "**Task** : Interpret the results you just got, and then compute the performance of a very simple baseline model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ddd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cabbcbe",
   "metadata": {},
   "source": [
    "It could definitely be better. Let's take a step back and reflect:\n",
    "\n",
    "1. We chose columns just based on their type. That means we ignored categorical data and didn't even check whether the values made sense.\n",
    "2. We trained the model once and never checked for overfitting. Oh, and we forgot to scale the inputs too.\n",
    "\n",
    "Maybe we rushed things a bit. Time to get back to the bread and butter of data science: data preparation.\n",
    "\n",
    "## Data quality\n",
    "\n",
    "**Task** : Use the [`isna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) method together with `sum` to check for missing values in the dataset and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01358d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d10626",
   "metadata": {},
   "source": [
    "**Task** : Use the [`describe`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) method to examine the distributions of the numerical variables, and then interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa73e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fc5545",
   "metadata": {},
   "source": [
    "The minimum values for *x*, *y*, and *z* are 0. So apparently... we have some 2D diamonds ?!\n",
    "\n",
    "**Task**: Display all observations where at least one of the three dimension variables is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff8ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd46695",
   "metadata": {},
   "source": [
    "Clearly, these *flat diamonds* make no sense for our study, they're just data collection errors.\n",
    "\n",
    "**Task**: Remove these observations, and report the dataset size before and after the cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b888f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17c8b30a",
   "metadata": {},
   "source": [
    "So far, we haven't really looked at any distributions. Let's explore the distribution of a column, say *carat*, and how it relates to the target.\n",
    "\n",
    "**Task**: Build a function explore_column with the following parameters:\n",
    "* *df*: the dataframe containing the columns of interest\n",
    "* *column*: the name of the column you want to inspect\n",
    "* *target_column*: the name of the target column\n",
    "\n",
    "The function should display, side by side, a histogram of the column and a scatter plot showing its relationship with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4828c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4234a9ec",
   "metadata": {},
   "source": [
    "**Task** : Use the previous function on the *y* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afc672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4d8e2c7",
   "metadata": {},
   "source": [
    "Looks like we have some outliers! These two points could seriously mess with our predictions because they don't follow the trend. To make this clearer, here's a small toy example illustrating the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af209b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "size = 100\n",
    "sigma = 0.25\n",
    "function_real = lambda x: x + 1\n",
    "\n",
    "x = np.random.normal(size=size)\n",
    "y = function_real(x) + sigma * np.random.normal(size=size)\n",
    "\n",
    "offset = 3\n",
    "random_index = np.random.randint(0, size)\n",
    "x[random_index] = x[random_index] + offset\n",
    "\n",
    "x_range = np.array([np.min(x), np.max(x)])\n",
    "\n",
    "model = LinearRegression().fit(x.reshape(-1, 1), y)\n",
    "function_learned = lambda x: model.coef_[0] * x + model.intercept_\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(x_range, function_real(x_range), ls='--', alpha=0.8, color=sns.color_palette()[0], label=\"Real function to learn\")\n",
    "plt.plot(x_range, function_learned(x_range), alpha=0.8, color=sns.color_palette()[2], label=\"Function learned\")\n",
    "plt.scatter(x, y, alpha=0.8)\n",
    "plt.scatter(x[random_index], y[random_index], color=sns.color_palette()[2], label=\"Outlier\")\n",
    "\n",
    "plt.title(\"Toy regression with outlier setup\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefccdc6",
   "metadata": {},
   "source": [
    "**Task** : Remove the outliers from the *y* column, then explore the other columns as needed. Make sure to print the number of observations before and after the cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305c800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74a8ec77",
   "metadata": {},
   "source": [
    "Next, we need to handle the categorical variables. A good way to explore them is with a violin plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_violin_plot(column, figsize=(12, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.violinplot(data=df, x=\"price\", y=column, inner=None)\n",
    "    plt.title(\"Distribution of price in function of %s\" % column.capitalize())\n",
    "    plt.show()\n",
    "\n",
    "make_violin_plot(\"clarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff2278",
   "metadata": {},
   "source": [
    "After carefully exploring all the categorical variables, it's time to transform them into a format our model can use. One-Hot Encoding is a good choice here.\n",
    "\n",
    "**Task** : Use the [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function to perform One-Hot-Encoding. Don't forget to check the number of columns before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf3fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5080f7a",
   "metadata": {},
   "source": [
    "How useful were all these preprocessing steps for our task? Let's find out by measuring performance again.\n",
    "\n",
    "**Task**: Split the data into training and test sets, then train the model and evaluate its performance on the test set. Compare the results to your previous predictions and provide some commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082aacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1c46034",
   "metadata": {},
   "source": [
    "So far, we've only measured performance *once*. Now, we're going to use cross-validation with the [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function.\n",
    "\n",
    "Since we want to use RMSE and MAE with cross_val_score, we'll need to wrap them using [`make_scorer`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b934fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, y, scoring=make_scorer(root_mean_squared_error), cv=5)\n",
    "mean_scores = np.mean(scores)\n",
    "std_scores = np.std(scores)\n",
    "name = root_mean_squared_error.__name__\n",
    "print(f\"{name}: {mean_scores:.4f} (+/- {std_scores:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748594a5",
   "metadata": {},
   "source": [
    "We want to understand how each part of our preprocessing affects prediction quality. To do this, we'll measure performance at each key step.\n",
    "\n",
    "**Task**: Define a function named train_predict with the following parameters:\n",
    "* *X*: feature matrix\n",
    "* *y*: target vector\n",
    "* *metric*: a performance metric\n",
    "* *cv*: number of folds for cross-validation\n",
    "\n",
    "The function should generalize the code from the previous cell so it can be reused for different preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753126a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac05e28b",
   "metadata": {},
   "source": [
    "**Task** : Write a cell that measure performance at each key steps of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b1cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbcd0d7e",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "Exploring your model's predictions—especially the errors—is a crucial part of improving it. This helps you understand how the model reacts to different inputs and can guide you toward better preprocessing, feature engineering, or even model improvements.\n",
    "\n",
    "**Task**: Inspect the errors of the model and reflect on what they reveal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
