{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d07cbd0",
   "metadata": {},
   "source": [
    "## Lab Work 2 : Linear Regression\n",
    "\n",
    "This notebook builds on the second lecture of Foundations of Machine Learning. We'll focus on the linear regression model.\n",
    "\n",
    "Important note: the steps shown here are not always the most efficient or the most \"industry-approved.\" Their main purpose is pedagogical. So don't panic if something looks suboptimalâ€”it's meant to be.\n",
    "\n",
    "If you have questions (theoretical or practical), don't hesitate to bug your lecturer.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this sequence, we are trying to predict the price of the stock TSM : a taiwanese manufacturer of GPU chips, mostly used nowadays in AI. Let's have a look at the features we have to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ee1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"TSM.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0c0f1",
   "metadata": {},
   "source": [
    "All of the above data comes from the [Yahoo Finance Python API](https://github.com/ranaroussi/yfinance). It gives access to all finance market data live listed on [Yahoo Finance](https://fr.finance.yahoo.com/). We choosed the daily close price of :\n",
    "* **Companies** : Taiwan Semiconductor Manufacturing ([TSM](https://finance.yahoo.com/quote/TSM/)), Nvidia ([NVDA](https://finance.yahoo.com/quote/NVDA/)) and Micron Technology ([MU](https://finance.yahoo.com/quote/MU/))\n",
    "* **Comodities** : Gold, Silver, Platinium, Paladium and Coppper. We couldn't get the silicon price because it is not freely available.\n",
    "\n",
    "Our hypothese is that theses tickers can help use predict TSM's stock price. Let's have a look first at his price through time :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.axvline(x=pd.to_datetime(\"2022-11-30\"), ls='--', color=\"black\", label=\"ChatGPT released\", lw=1)\n",
    "plt.plot(df[\"TSM\"], label=\"TSM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b4731",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "We need to go a bit deeper.\n",
    "\n",
    "**Task** : Use the [`scatter_matrix`](https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html) function to start exploration relationship between all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a154ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "307b5c72",
   "metadata": {},
   "source": [
    "**Task** : Use the [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function with the [`corr`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) method on the dataframe and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0603efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a958c5d",
   "metadata": {},
   "source": [
    "**Task** : Given the previous cells, make a choice on which columns to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d174e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0c1947e",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Before we continue, we need to split the training and test set. In our setup, doing it randomly with [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) will lead to data leakage. Indeed, we might train on future data and test on data from the past, so we need to split according to time.\n",
    "\n",
    "**Task** : Define a `train_test_time_splitting` function that split a matrix of feature *X* and a target vector *y* according to a *train_ratio*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f42c08",
   "metadata": {},
   "source": [
    "Now we need to build time series specific features. As we have daily closing price, we can't used them to predict *directly*. Instead, we can compute features based on the past values :\n",
    "\n",
    "* **Lags** : the last value for a given period. One can use the [`shift`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html) method for a vector.\n",
    "* **Rolling** : the average or standard deviation of the previous values for a given period. One can use the [`rolling`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html) method for a vector alongside the `mean` and `std` functions.\n",
    "* **Return** : the evolution across a given period. One can use the [`pct_change`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html) method for a vector.\n",
    "\n",
    "**Task** : Define a function that build lags, rolling and return features (each being optionnal) for a dataframe and specifics columns. Also specify the periods length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe390f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5e0efd",
   "metadata": {},
   "source": [
    "**Task** : Use the previous function to compute rolling features of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2882c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a9268cd",
   "metadata": {},
   "source": [
    "## Modelisation\n",
    "\n",
    "Let's recap what we have learned so far, including the previous session :\n",
    "1. A linear regression needs its input to be float and standardized : we use the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to this end\n",
    "2. It is easier to wrap the previous step with learning using a [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "3. We need to split the dataset into train and test set according to time, using our own `train_test_time_splitting` function\n",
    "4. We shall have a way to compare our work to a strong baseline. Here we will take the rolling average of TSM stock value in the last 7 days.\n",
    "\n",
    "\n",
    "Common metrics to assess the performance of a regressor are, given a dataset of $n$ sample, ground truth vector $y$ and predicted values vector $\\hat{y}$:\n",
    "* **Root Mean Square Error** ([`RMSE`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html)) : penalize more large errors than MAE\n",
    "$$ RMSE(y, \\hat{y}) = \\sqrt{\\frac{1}{n} \\sum_{k=1}^n (y_k - \\hat{y}_k)^2}$$\n",
    "\n",
    "* **Mean Absolute Error** ([`MAE`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)) : penalize smaller errors more than RMSE, all errors *weights* the same\n",
    "$$ MAE(y, \\hat{y}) = \\frac{1}{n}\\sum_{k=1}^n \\left|y_k - \\hat{y}_k\\right|$$\n",
    "\n",
    "* **[$R^2$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) Score** : bounded above by 1, gives insights on how well the model grasps the *structure*. Note that $R^2$ can be negative.\n",
    "$$ R^2(y, \\hat{y}) = 1 - \\frac{\\displaystyle \\sum_{k=1}^n (y_k - \\hat{y_k})^2}{\\displaystyle \\sum_{k=1}^n (y_k - \\overline{y})^2}$$\n",
    "\n",
    "\n",
    "**Task** : Define a function that takes a dataset with features, the target column and the features columns. Then the function will split, train and display performance on the test according to the three above metrics, and display the performance of the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc9c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ca779d",
   "metadata": {},
   "source": [
    "**Task** : use this function for our purpose using only TSM and NVDA rolling avg features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc828dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201a41c9",
   "metadata": {},
   "source": [
    "Our model performs worse than the rolling average baseline, yet showing great metric performance. We need to improve our model.\n",
    "\n",
    "## Doing better\n",
    "\n",
    "**Task** : Run the following cell and analyze its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b096305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ec37f8",
   "metadata": {},
   "source": [
    "We see that the trend between TSM stock closing price and NVDA's are not linearly related, but they are with a root square ! Therefore, to *help* the linear model, we shall switch from *pure* NVDA's stock values to square root values. Obviously, one need to check that it works with all rolling average column related to NVIDIA.\n",
    "\n",
    "**Task** : Implement the described idea. Then, train again a model using these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc880f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef76cfe",
   "metadata": {},
   "source": [
    "Now, this is better !\n",
    "\n",
    "**Task** : Keep trying ideas to outperform even more the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
